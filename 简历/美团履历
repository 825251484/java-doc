一、简历
项目介绍：KeeTa是美团推出的全球外卖品牌，致力于服务全球客户，打造一线外卖品牌。系统大致分为D端，B端，C端，M端。本人主要负责D端系统的研发，D端细分人员系统，培训系统，管控系统等。注册骑手数达30w，骑手抽检QPS100，全球平均每日单量达20w单左右
工作职责：业务：负责管控项目的研发，骑手抽检、异常上报、判责处罚申诉、培训等业务开发。技术：代码重构，告警治理，公共组件开发，实践和落地AIcoding，欧洲机房迁移
个人亮点：
	1、精通使用设计模式，骑手异常报备场景，多种设计模式结合。
	2、精通使用各种中间件，mafka消息队列延迟消息私信队列等，squirrel缓存，分布式锁等，crena定时任务等
	3、精通使用mysql，成熟的实战经验，在团队中分享过sql优化经验

项目介绍：美团直播是美团平台的核心项目，隶属于美团平台视频技术部，产品包括：主播端直播系统、观众端直播间两大部分，本人主要负责b端和c端货架商品相关功能开发，直播间内商品查询峰值QPS 6W，峰值在线人数21w
工作职责：业务：本人主要负责货架功能开发，设计商品上下架，分组，讲解等，以及提供SPI通用的数据模型对接下游不同的商品类型。技术：直播间货架分布式锁，c端货架查询性能优化，核心接口异常监控建设
个人亮点：
	1、核心接口查询优化：本地缓存+线程池并行查询+流量打散
	2、核心接口异常监控：为了解决代码变更导致的线上问题，搭建diffset，转发少量请求，diff查询结果
	3、货架增删改操作串行化，为了保证商品数据排序的一致性。对商品增删改加锁。
	4、异步上传优化：上传大文件超时，优化成异步并实时更新上传进度，优化用户体验


二、项目难点
1、c端货架核心接口，小黄车商品查询接口
  1）背景：当置顶操作时，会推送给所有用户，这个时候所有用户会自动刷新货架，瞬间大量请求查询c端货架，也就是小黄车的商品列表，
  2）问题一：流量突增，可能导致mysql集群压力增加，cpu飙升，主从同步延迟，链接被占满，导致新请求被拒绝等问题，甚至拖垮其他服务
      解决方案：使用Caffeine本地缓存，设置500ms刷新时间，设置1s兜底过期时间，采用异步更新缓存，允许在1s内读取到旧值，解决了db的压力，本地缓存可以挡住大部分流量
  3）问题二：流量突增，可能会打垮下游服务，导致下游服务cpu飙升，线程池打满，触发限流熔断，大量请求失败，无法返回商品信息。
      解决方案：前端流量打散，在置顶操作后，后端发送pike消息给前端，携带随机数，和直播间id，通过随机延迟0-5s，请求后端。
              后端请求合并+多线程请求：将相同类型的商品合并到一个集合中，对下游发起批量请求。引入线程池并行访问，不同商品类型，同时访问不同的下游服务。
  4）问题三：qps 6w是怎么得来的，你做了哪些优化，优化前后有什么变化？
	答：1、先服务拆分：bc两个服务，2、接口优化，优化之前，300台机器，压测qps 1w，平均每台qps30多。已到极限，cpu使用率已超过90，响应时间也变长。优化之后：500台机器，压测 10w qps，平均每台qps 200，cpu使用率在60%左右，平均响应时长200ms，cpu使用率不高是因为请求下游耗时比较多。
		日常：机器200台，集群qps在1w左右。每台大概50qps，cpu使用率在20~30%左右
  5) Caffeine的特性和缓存策略：1、当缓存中没有数据的时候，去读取db。读取db这个操作是通过方法computeIfAbsent（ConcurrentHashMap中）来实现的。也就是说100w的请求过来，也只有一个线程去去读取db。其他线程阻塞，不会给db造成压力。
	2、异步刷新缓存可以设置线程池数量，比如我设置2个线程，在读取数据的时候发现超过设置的时间，就需要触发异步刷新，那么当我100个请求来读取，满足异步刷新逻辑，会生成2个异步线程刷新，但是这个100个请求返回的是旧的数据。
  6）如果流量突发扩大100w，没有任何征兆该怎么办？
	1、做好防御，创建直播间时将商品基本信息缓存为null。当流量突增时，依然可以保护db，然后设置异步刷新机制，最多2个线程，时间设置500ms。流量徒增时，暂时显示时null，但是异步刷新可以快速跟新缓存（如果货架商品后有变更的话）
	2、做好热点检测，定时任务每秒，查询统计一下直播间人数，如果超过10s，主动将缓存写入到缓存中，如果你没有设置缓存并且没有预热操作，那么流量突增就会打到db。如果热点检测，就是提前预热
	3、流量突增下游扛不住：做2层缓存，一层商品基本信息，另一层商品详情信息，先查询第一层，在查询第二层。如果第二层没有在查询下游服务。结合热点检测，将这2层缓存提前写入到缓存。这样虽然牺牲了数据的一致性，但是详情页可以保证数据准确，并且有效的保护了db和下游服务。
   7）线程池隔离，并行查询下游服务
	项目启动时，将商品类型对应的线程池放入map中，然后请求执行时，从map中获取对应线程池。并提交给线程池，通过CompletableFuture.supplyAsync提交任务。
	然后，合并所有结果CompletableFuture<Void> allDone = CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]));
		allOf原理：回调机制+计数器，每一个异步Future完成，回调通知主线程，主线程对计数器减1，知道为0，所有异步线程执行完。此过程不消耗cpu。比轮训方式更好
	然后循环allDone获取结果，allDone已经是所有就绪的结果
	
2、核心接口异常监控建设
  1）背景：核心接口对于整个系统相当重要，任何的变更可能会引入一些潜在的风险，导致线上生产问题，所以为了提前感知到核心接口的异常，搭建一个diffset分组
  2）问题一：代码变更，或配置变更，导致核心接口不可用，或者引入生产bug
      解决方案：我们搭建了一个diffset分组，也就是灰度set，代码变更，先发布diffset分组，该分组有2台机器，会有少量流量进入这个分组（只有diffset才会进行比对，默认分组不会发起异步diff），

3、商品授权
   背景：商家将商品授权给直播间
   1）难点1: 数据存储。庞大的数据量
	解决方案：使用mysql+es存储，mysql存储基本信息，用于校验，简单根据索引查询，es用作分页及复杂查询。保证数据的一致性使用，先更新mysql在更新es，如果es报错，回滚mysql，但是极端场景es没法回滚
   2）难点2：权限的控制：两个授权平台，数据模型是一样的，通过类型区分是哪个平台配置的。每个商品可以给1～2000主播授权，也可以选择全部主播，授权之后可对该商品直播。那么当权限变更时，会实时更新直播间权限，因为配置商品量比较大，每个商品对应的主播又比较多，如果这个商品对应全部主播，那就要实时更新全部主播间，主播大概5w个，直播间大概10w左右，庞大的数据更新，我们使用mq mafka异步更新，最多一瞬间可产生几十万的消息量。所以要考虑消费着出现积压的情况。
	解决方案: 我解决积压思路：
	1、提高系统的性能，1️⃣过滤无用的数据，比如一些直播间无该商品，或者直播间状态已结束，这些直接过滤，不用走更新逻辑。2️⃣消费者采用线程池并发处理，提高处理效率
	2、从mafka角度增加分区，8个生产者，mafka集群4台机器，每台机器4个分区，一共16个分区。对应16个消费者，消费者集群三百多台机器
	3、最大数据量500*2000=100w
		100w➗300秒 = 3333条，每秒钟需要处理3333条。要求5分钟内同步完。
		如果有16个消费者：3333 / 16 = 208条，每个消费者每秒需要处理208条
		消费者p999 = 50～200之间，那就按200ms算，那就是每秒可以处理5条消息，远不及208条，所以，在消费者开启线程池并行消费，使用线程池，核心线程16台，最大线程32，用5*32=160条，基本接近200条了。这是按最慢速度消费计算的
		如果在增长一倍，那就需要开启并行消费的能力，消费能力可以成倍增长。

4、分布式锁

5、直播家商品导入
背景：同步导入，最大500条，经常超时，原因：先查询下游，在插入直播表，在插入最近添加表，在封装excel结果，在封装url，给前端下载
解决：异步导入，前端调后端接口，立刻返回，后端异步处理导入，创建上传记录表，记录上传的状态，进度，时间，总数，url等信息，然后分两个阶段，查询和插入，。然后将商品分批，没导入一批，进度增加一块，通过pike消息。
如果前端关闭页面或者网络问题，无法收到pike消息，那么主播再次进入直播间时，会主动查询，后端接口获取最新上传进度。异常时会更新状态。

5、mysql死锁（货架分布式锁-串行化）：
背景：直播间批量删除100个商品，每次20个循环删除，为了保证排序准确，商品变更发送kafka消息，异步兜底对商品进行重新排序，死锁出现在，批量删除和兜底排序，批量删除锁住前10个商品，兜底排序锁住后10个商品，锁住自己的10个商品同时互相获取对方商品10个商品，
串行：对上下架，添加删除，排序等操作，加上直播间锁，使用aop分布式锁。在方法上添加锁的注解。任何写操作先获取锁在执行逻辑，执行完在释放



外卖
1、业务背景：骑手异常报备和骑手装备抽检，异常报备场景：商家出场慢，未营业，地址错误，大订单等。
	流程：骑手端上报，或者提交抽检照片，需要先调审核平台，创建审核任务，创建之后审核平台发送mq，我们消费，这里包含多种类型的消息，根据消息类型，封装不同参数，调大模型接口，返回具体信息：商家地址距离，未营业照片等等。然后根据模型返回信息，调用事实平台，就是正则表达式，返回true/false，根据结果判断是否审核成功/失败，然后在回调审核平台更新结果。
	问题：
	1）、业务高峰期，大模型接口性能差，导致业务之间互相影响，并且消息挤压严重，
	3）、装备抽检-下游出现问题，我们需要降级，直接通过审核，但是这种不合理，并没有更绝结果审核
	方案：
	1）、将消息分为：即使消息，非即时消息，减少互相影响，减少积压，收到消息后，分别投入到两个topic中。
	2）、非及时消息降级，我们希望等下游灰度后，重新调用下游，所以降级之后把消息放入死刑队列

2、欧洲机房迁移
业务背景：为服务好全球更多的用户，以及海外市场的迅速扩张
三步走：
	1）服务改造+欧洲机房部署
	2）全局服务全量切换：用户画像，会员信息，全局配置等
	3）本地服务灰度切换：根据前端标识路由到欧洲机房，灰度放量
	4）沙特本地服务全部切换到欧洲机房。数据机房内闭环。
	其他：1、sre将现有中间件复制一份出来，开发工程改造。根据机房香港和欧洲，建两个机房文件夹，每个文件夹下包含dev。test.prd等多环境的配置文件，在项目启动时加载不同文件夹下的对应的配置。
	    2、部署上线，mafka完全独立部署，mysql数据互相同步。

3、多种设计模式，通用化业务和个性化
	1）提交抽检：策略模式
	2）完单抽检：责任链模式+模板模式+延迟消息+消费者策略模式：时间>60分钟。完单数量命中随机数【5～10】或者数量>10,触发抽检。通知骑手，生成延迟判责，延迟作废
	3）报备链路：策略模式+模板模式+审核任务异常创建+审核回调+调用大模型+模型异步回调+

4、慢sql问题
   1）背景：定时任务：执行t+1周期聚次处罚，根据region获取所有城市，根据城市获取当前时间，根据时间查询处罚任务表，返回需要最大id和最小id（索引覆盖），然后根据时间，城市id，时间查询，按照主键排序，分页查询前100条，每次都查询前一百条，无深度翻页。
	select * from where ... order by id limit 100;
      现象：查询结果100条时，好事100ms，剩余最后不满足100条时，耗时2s，并且有主键索引id，时间索引，城市id索引
      原因：1、由于存在多个索引，mysql优化器会综合考虑索引的使用情况，因为sql中有order by id，通过执行计划可以看到，使用的是主键索引。主键索引是聚族索引，叶子节点存储的是数据行，那么mysql会扫描主键索引树，查询全部数据，然后进行过滤。也就是约等于“全表扫描”。
但是执行计划type=index而不是等于all，就是因为mysql强调通过主键索引来扫描的，而非无差别的行扫描。
	2、当ORDER BY和LIMIT一起使用时，MySQL在找到所需数量的行后会停止排序查询。否则直到扫描全部数据



三、描述自己的项目
背景：
架构：两个项目：一个骑手app管控服务：判责处罚，抽检报备申诉的核心逻辑，一个运营管理平台服务：管控数据配置查询等。mysql存储，redis分布式，kafka消息
难点：外卖这个项目流量和并发度都很低，难点主要体现在业务的复杂性，所以对我而言的挑战点就是代码设计上，如果兼容各种复杂的场景。举例说明





四、工作中遇到的问题
外卖项目：大数据结果数据需要记录日志表，用来做问题排查，代码bug导致，异常时没有写表，先修复问题，然后回溯kafka消息




11、直播c端货架接口
熔断器配置
统计窗口：10秒
触发条件：请求总数>= 20且失败率>= 50% 且失败数>= 2
服务限流配置：CPU利用率平均值 >= 50%，单机入口总限流：正常流量: 9999/秒
业务接口限流：正常流量: 5200次/秒，压测流量: 180000次/秒





mysql版本：5.7.26-30205-log

直播
服务集群：goods主播端：40台，8核/16G/150G，trade观众端：160台，8核/16G/150G，query查询服务：280台
mysql集群：1主17从，机器配置：独享容器/ 24核/ 140 GB/ 磁盘PCIE-SSD 2900GB / 千兆网卡，数据量：2亿
es：11节点分片，4C/8G/200G

外卖
服务集群：govern：12台，8核/16G/300G，governadmin：6台
mysql集群：1主7从。机器配置：腾讯云虚拟机/ 32核/ 64 GB/ 磁盘Unknown 1200GB/ 千兆网卡

redis版本：
直播项目redis集群：20主100从
集群容量：100.0GB
主节点机房：月浦、浦江、嘉定
从节点机房：月浦、浦江、嘉定

外卖项目redis集群：3主9从
集群容量：15.0GB
主节点机房：香港03、香港02
从节点机房：香港03、香港02
