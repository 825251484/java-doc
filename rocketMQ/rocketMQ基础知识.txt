⚫为什么要用rocketMQ?
异步解耦；异步处理请求，系统之间互不影响干扰。
削峰限流：比如系统中某个接口可以处理请求数是2k，如果访问任务远超承受的访问，那么可以使用mq来解决，比如把5000个消息先放入mq，然后每次消费1000个，剩下的放在Broker堆积慢慢消费就好
分布式事务一致性：可以做分布式事务，保证数据最终一致性
大数据分析：kafka


⚫生产者发送消息方法
同步：把消息发送到rocketmq服务器，阻塞并等待返回结果，拿到结果才能发送下一条
异步：把消息发送到rocketmq服务器，不用等待其返回结果，就可以发送下一条消息
单向：只管发送。消息可靠性不高，可能丢失消息，但是


⚫消费者接收消息方式
并发：MessageListenerConcurrently：内部通过线程池来创建多个线程，进行消费，批量消费
按顺序：MessageListenerOrderly：一次消费一个


⚫消息类型
1.普通消息：
2.顺序消息：生产者保证消息的顺序性，
	1.保证生产者顺序发送。同步单线程发送
	2.保证相同业务的消息放入同一个队列。并且顺序同生产者发送消息的顺序是一致的
	3.消息者单线程接收消息，保证消息顺序同队列中消息一致，使用监听者MessageListenerOrderly，一次消费一个
3.广播消息：
	1.集群模式：消费者是集群部署，每条消息只会被分发到一台机器上进行消费，失败重投后，不保证路由到同一台机器上
	2.广播模式：消费者集群部署，每条消息都会被集群下每个消费者处理
		问题：1.消费失败，不会重投消息，因此消费者要做消费失败的处理
			  2.每一次重新都从最新的消息开始消费，客户端在停止期间，发送到rocketmq服务器的消息，将会被跳过，从最新的消息开始消费
			  3.较少使用
			  4.消费者广播模式设置： consumer.setMessageModel(MessageModel.BROADCASTING); //设置广播模式
4.延时消息：订单取消
	1.rocketmq消息是存储在commitlog中，服务内部有一个内置队列，topic是SCHEDULE_TOPIC_XXXX，这个topic对用18个队列。因为rocketmq延时不是任意设置，而是固定18种时间。每个时间对应一个队列
	2.rocketmq服务会根据延时等级将消息地址/偏移量存在内置队列中，并把topic替换成SCHEDULE_TOPIC_XXXX，然后用一个定时器，去轮询队列中，是否有消息到期
	3.如果消息到期就把消息取出来，恢复之前得topic，放入目标队列中，消费者就可以消费这条消息了
	4.message.setDelayTimeLevel(3); //发送者设置延迟等级
5.批量消息：
	1.可以一次性发送多条message，也就是message集合，但是一批消息得大小不能超过4M。如果超过4M，可以对消息拆分，分为多次发送。
	  类似于循环发送消息，然后消费者并发接收消息，MessageListenerConcurrently内部线程池，开启多线程消费。线程数量可通过参数控制
	2.计算消息的大小 = (topic + body + （key + value) * N) * 吞吐量
6.过滤消息：
	1.通过tag方式过滤
		生产者： String[] tags = {"TAGA","TAGB","TAGC"};
				 String tag =   tags[i%tags.length];
				 Message msg = new Message("TopicTest",tag, ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));//每个消息设置一个tag，tag二级分类
		消费者：
				consumer.subscribe("TopicTest", "TAGA || TAGB");//过滤tag进行消费，只要tag = TAGA || TAGB
	2.SQL表达式方式
		生产者：
			Message msg = new Message("TopicTest" ,tag,("RocketMQ消息测试，消息的TAG="+tag+  ", 属性 age = " + i + ", == " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
			msg.putUserProperty("theage", i+""); // 每个消息设置属性值 theage ，值 0-9
		消费者：
			consumer.subscribe("TopicTest", MessageSelector.bySql("theage between 0 and 6")); 
7.事务消息：
	1.什么是事务消息：
		生产者本地事务和生产者发送消息得事务。保持最终一致性。事务消息是通过二阶段提交来实现得。准备阶段和提交阶段
	2.工作流程
		① 生产者发送半事务消息，rocketmq服务端返回半事务消息发送成功
		② 生产者查询本地事务结果，将本地事务结果发送给mq服务端。
		③ 服务端根据本地事务得结果commit：投递消息给消费者、rollback：不投地消息存储三天后删除
		④ 如果服务端没有接收到生产者本地事务消息结果的反馈，那么mq服务端会每隔一分钟，回查消费者本地事务的结果,根据回查结果commit或者rollback
		⑤ 如果回查15次还是没有查询到结果，这个消息将被删除（默认：private int transactionCheckMax = 15; private long transactionCheckInterval = 60 * 1000;）
	3.工作原理
		mq服务端有两个内置topic，一个付责存储一阶段提交的半事务消息。另一个存储二阶段提交的本地事务的结果commit或者rollback。
		会根据二阶段的结果commit，把事务消息重新投递到正常的topic中，这时消费者就能发现这个topic，就可以消费这条消息了，如果rollback：不投地消息，在内置topic中，存储三天后删除
		那么服务器是怎么判断这个半事务消息是否要回查呢？
		通过第一个topic和第二个topic对比，第一个topic存储的是所有半事务消息。第二个存储的是只有返回结果的消息。通过第一个topic-第二个topic，能找到第一个topic中没有返回事务结果的消息。然后进行回查
		HALF消息:RMQ_SYS_TRANS_HALF_TOPIC(第一阶段：临时存放消息信息)
		OP消息: RMQ_SYS_TRANS_OP_HALF_TOPIC(第二阶段：记录⼆阶段操作)
		RMQ_SYS_TRANS_HALF_TOPIC-RMQ_SYS_TRANS_OP_HALF_TOPIC = 消息回查消息



⚫NameServer的原理及作用
1.NameServer作用
	当发出请求服务时,客户端通过注册中心服务知道所有的服务实例。客户端使用负载均衡算法选择可用的服务实例中的一个并进行发送。
2.路由注册
	在broker启动的时候，和每个NameServer建立长连接，并发起注册请求。NameServer内部维护了一个broker列表。broker会每隔30发送一次心跳包，其中包含了：broker地址名称，集群信息，队列等信息，
	nameserver接受到心跳包。会更新时间搓。记录broker最新存活时间
3.路由剔除
	正常情况下，如果Broker关闭，则会与NameServer断开长连接，Netty的通道关闭监听器会监听到连接断开事件，然后会将这个Broker信息剔除掉。
	异常情况下，NameServer中有一个定时任务，每隔10秒扫描一下Broker表，如果某个Broker的心跳包最新时间戳距离当前时间超多120秒，也会判定Broker失效并将其移除。
4.路由发现
	在我们创建生产者和消费者时，都会指定topic。那么在消费者和生产者启动时，就会根据topic，从NameServer中拉取注册的broker信息。缓存到本地，然后每隔30s拉取最新的broker信息
5.NameServer如何保证数据的最终一致？
	在rocketmq设计之初使用的是zk作为注册中心。zk是强一致性解决方案，比较重量级。所以后来rocketmq自己设计了一个轻量级的，只需要保证数据最终一次性，不需要依赖另外的中间件。所以NameServer就诞生了
	NameServer每个节点是独立的。节点之间不互相通信。那么是如何保证最终一次性：请看路由注册原理
	
⚫Broker的原理及作用
Broker是RocketMQ的核心，消息存储是broker的核心，提供了消息的接收，存储，拉取等功能，为了保证broker高可用，都是集群部署
多主多从。主服务器可读写，从服务器可读不可写，主服务器挂了以后。消费者可读取从服务器消费

⚫Producer:在启动的时候会根据topic，去NameServer拉取对应的broker信息。缓存到本地。然后每隔30S更新一次本地breker信息

⚫Consumer:同Producer原理

⚫Topic：类似于一级分类。一个大的分类。逻辑上的分类

⚫Queue：一个topic对应多个queue，用于并行发送和接收消息，达到一个水平扩展的目的。也是提高队列的吞吐量吧。同时多个队列可以在消费时采用负载均衡策略，可通过参数设置队列数量

⚫Producer Group：简单来说就是多个发送同一类消息的生产者称之为一个生产者组。一个生产者组，代表着一群topic相同的Producer。

⚫Consumer Group：消费同一类消息的多个Consumer实例组成一个消费者组。一个消费者组，代表着一群topic相同，tag相同（即逻辑相同）的Consumer。通过一个消费者组，则可容易的进行负载均衡以及容错
注意：一个消费者可以消费不同的队列，但是这个队列如果被一个消费者消费了，那么同组其他的消费者就不能消费这个队列了。就是说：同一个队列不能被同一个消费组中的不同消费者消费

⚫Message：一个message必须设置一个topic，同时可以设置tag用户消息过滤

⚫Tag：对topic更细致的分类，类似于二级分类

⚫Offset：是指在某个topic下，对应队列中的位置。可以通过这个位置定位到消息，同时也可以告诉消费者从哪里开始向后继续消费
Offset分类：
	集群模式下：也就是同一个Consumer group里的多个消费者每人消费一部分，各自收到的消息内容不一样，由Broker端存储和控制Offset的值，使用RemoteBrokerOffsetStore结构 。每个消费者offset都不一样
	广播模式下：每个Consumer都收到这个Topic的全部消息，各个Consumer间相互没有干扰， RocketMQ使用LocalfileOffsetStore，把Offset存到本地 (消费者)。
注意：Consumer. setConsumeTimestamp(),可以通过参数设置消费者从哪里开始消费，但是消费者重启后，该参数将失效。会接着上次offset继续消费
集群模式下：offset的存储格式：
private ConcurrentMap<String, ConcurrentMap<Integer, Long>> offsetTable = new ConcurrentHashMap(512);
{
"offsetTable": {
	"test-topic@test-group": {//topic@消费者组
		"0": 88526, //队列ID:offset
		"1": 88528
		}
	}
}


⚫rockermq集群：
broker集群：
主从复制分类：
同步：数据可靠性更高，性能差一点
异步：性能好，但是可能存在消息丢失的问题
要保证数据的可靠性，需要采用同步刷盘，同步双写的方式，但性能会差一点
rockermq普通集群双主双从：不能自动选主，所采用Dledger（raft一致性协议）方式搭建集群：可以自动选主
问题：在master宕机时，消费者转向slave节点消费消息，但是可能从节点还没有复制完消息。所以可能暂时会有少量消息丢失的问题，如果主节点恢复，丢失的消息最终也会被消费


⚫集群工作流程：
1) 启动NameServer,NameServer起来后监听端口,等待Broker,Producer,Consumer连上来,路由控制中心
2) Broker启动,跟所有的NameServer保持长连接,定时发送心跳包,心跳包中包含当前Broker信息以及存储所有Topic信息,注册成功后,NameServer集群中就有Topic跟Broker的映射关系
3) 收发消息前,先创建Topic,创建Topic需要指定该Topic要存储在哪些Broker上,也可以在发送消息时自动创建Topic
4) Producer发送消息,启动时先跟NameServer集群中的其中一台建立长连接,并从NameServer中获取当前发送的Topic存在哪些Broker上,轮询从队列列表中选择一个队列,然后跟队列所在的Broker建立长连接从而向Broker发消息
5) Consumer跟Producer类似,跟其中一台NameServer建立长连接,获取当前订阅Topic存在哪些Broker上,然后直接跟Broker建立连接通道,开始消费消息


⚫消息存储
rocketmq是通过文件系统来存储的消息，每个文件大小1G，超过1G会生成新的文件，
其内部结构中有一个commitlog存储着消息，comsumeQueue中存储着消息的索引。一个queue对应一个comsumeQueue，消费者消费消息先找到队列中的索引，然后通过索引查找消息消费


⚫消息投递机制：
生产者投递策略
	1.queue队列轮训投递策略（默认）：生产者轮训向每个队列投递消息。可以让消息均匀的分布在不同的消息队列上
	缺点：由于队列分布在不同的机器上，有的队列消息堆积或者网络问题，导致消息投递延迟。会影响后续的队列消息投递。所以
	2.基于Queue队列轮询算法和消息投递延迟最小的策略投递：
	RocketMQ在每发送一个MQ消息后，都会统计一下消息投递的时间延迟，根据这个时间延迟，可以知道往哪些Queue队列投递的速度快。
	 在这种场景下，会优先使用消息投递延迟最小的策略，如果没有生效，再使用Queue队列轮询的方式。
	3.【顺序消息】类型的投递方式：
		1.随机分配策略：随机数选择算法
		2.基于hash分配策略：根据hash值，队列数取余
		3.机器机房位置分配策略：机器就近原则
消费者如何选择队列：
	AllocateMessageQueueAveragely 平均分配算法：先平均剩下的队列按顺序分配
	AllocateMessageQueueAveragelyByCircle 基于环形平均分配算法：队列组成一个环。每个队列是一个节点。然后按照环的顺序每个节点分配一个消费者，消费者可重复分配
	AllocateMachineRoomNearby 基于机房临近原则算法：为了防止跨机房带来的网络延迟，不稳定等因素，根据机房和消费者的位置，就近选择机器
	AllocateMessageQueueByMachineRoom 基于机房分配算法：比如broker名称按照机房的名称进行拼接，在算法中通过约定解析进行分配。
	AllocateMessageQueueConsistentHash 基于一致性hash算法：将consumer消费者作为Node节点构造成⼀个hash环，然后queue队列通过这个hash环来决定被分配给哪个consumer消费者。
	AllocateMessageQueueByConfig 基于配置分配算法：根据配置分配


⚫消息的push和pull模式
push：服务端主动向消费者推送消息。这种模式一旦有数据就会推送给消费者。实时性比较好，也无需处理无消息的情况，但是客户端处理能力低，会导致消息积压在客户端
	实现方式：push方式里，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。
pull：消费者每隔一段时间拉去一批消息。不会有消息堆积的问题，但消费消息不及时，并且无消息时，会浪费连接，而且不知道服务端什么时候有消息，拉去消息间隔不好控制
	实现方式：pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue
rocketmq采用的DefaultMQPushConsumer模式表面看是推模式：实则是在pull模式基础上，做了一层封装，消费者每隔一段时间拉取消息时，如果有数据那就立即返回，
如果没数据，会一直保持该连接，直到有数据返回，如果超过30S还没有数据，那就请求超时，断开连接，然后再次发送拉取数据请求


⚫消息重试
1.顺序消息重试：每个1S重试一次。并且如果消费失败，不断重试，将导致后续消息被阻塞。既然是顺序消息，就要保证消息的顺序，如果破坏了消息的顺序，会带来数据上，业务上的错误
			  所以如果顺序消费失败，重试次数超过16次，扔失败，那么会放入死信队列，死信队列一般都是代码bug导致，所以这个时候就要人工介入
2.其他消息重试：随着重试次数增加，每次间隔时间越长，最长间隔2小时，默认重试16次，超过16次将不会再投递，并放入死信队列
3.什么样消息算失败？
	1.消费端返回ConsumeConcurrentlyStatus.RECONSUME_LATER（推荐）
	2.返回 Null
	3.抛出异常
4.注意：可以设置消息不重试。调整重试次数，消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。


⚫死信队列（DLQ）：
1.命名：%DLQ% + Consumer组名，如：%DLQ%online-tst
2.特点：
	不能被消费者正常处理的消息，重试次数超过最大次数。就会进入死信队列
	死信队列中的消息不能被消费，对消费者是不可见的
	死信存储有效期与正常消息相同，均为 3 天，3 天后会被自动删除
	每个死信队列对应一个groupid，无论是哪个topic，就是一个消费者组共享一个死信队列
3.如何处理：
	进入死信队列，是消费者无法正常消费，可能是又代码bug引起，所以可以根据消息定位到代码中，找到问题，然后可以在控制台重新发送该消息，或者消息重新投递到原来topic中，重新消费


⚫消息幂等
1.什么是幂等：一个操作处理一次和多次所产生的结果是一致的。所有称这个操作是幂等的。
2.为什么做幂等性处理：为了防止重复消费导致业务处理异常。
3.哪些场景造成消息重复：
	1.消费者返回ACK时失败，（网络闪断或者消费者宕机），服务器会尝试重新发送（消息重试）。
	2.reblance导致消息重复，比如Consumer1在消费万消息之后，Broker会记录消费者消费到哪个位置的offset(异步记录offset)，
	但是还没有记录之前，发生了reblance，这个时候Consumer2将会从旧的offset开始消费。导致Consumer1已经消费的消息，在Consumer2会再次消费一次

4.怎样实现消息幂等？
	rocketmq并没有做消息去重。所以消息幂等需要业务方自己去控制。
	1.乐观锁方式：
		插入：根据业务插入一条唯一的记录（唯一主键字段），插入成功代表第一次消费，插入失败不做业务处理，注意：需要让插入记录和业务处理放在同一事务中
		更新：数据更新时条件带上状态，例如：where statu = 1（数据库排他锁），更新成功代表第一次消费，更新失败，代表重复消费，不做处理
	2.分布式锁：
		可以通过业务上唯一标识来控制消息幂等，比如订单号，水流号等，第一次消费后，把唯一标识存在redis或者关系型数据库中，第二次先查询是否存在该记录，不存在则消费消息，存在则不做处理，
		先查询在更新/插入，由于存在并发消费，该流程不是原子操作，所以采用分布式锁保证线程安全。
	
	
	
	
	1.可以通过业务上唯一标识来控制消息幂等，比如订单号，水流号等，把唯一标识存在redis或者关系型数据库中，消息消费以后更新以下该业务的状态。下次重复消息时，先判断以下消息状态，如果消费过，那就不做处理
	2.但是上述方案在并发消费时，会有线程安全问题。可能导致状态更新出现问题，所以使用数据库锁，或者乐观锁，分布式锁等机制来处理，但是不建议使用悲观锁，降低系统的吞吐量，
	如果是并发插入的场景，可以设置唯一索引字段比如订单号，并且需要让插入记录和业务处理放在同一事务中
5.什么框架不做去重处理？
	如果在RocketMQ中实现消息去重实际也是可以的，但是考虑到高可用以及高性能的需求，如果做了服务端的消息去重，RocketMQ就需要对消息做额外的rehash、排序等操作，
	这会花费较多的时间和空间等资源代价，收益并不明显。


⚫rebalance触发场景和危害
	1.什么教rebalance机制：将一个topic下多个队列，并且在同一个消费者组下多个消费者实例之间进行重新分配。
	2.rebalance机制的目的：为了提高消息的并行处理能力，例如5个队列一个消费者，如果再加入一个消费者，那么5个队列就要重新分配给2个消费者，这样就提高了消息的并行处理能力
	3.rebalance触发场景：
		队列变化：队列扩容、缩容，broker其中一个节点宕机
		消费者变化：消费者数量增加减少，网络异常导致消费者与broker断开连接，消费者宕机等
	4.rebalance限制：在某个消费者组下，如果消费者数量大于队列的数量，那么会导致多余的消费者分配不到任何队列
	5.rebalance危害：
		消费暂停：比如增加一个消费者，会触发rebalance机制，导致短暂暂停原来的消费者，重新分配队列。
		消息堆积：如果暂停时间过长，会导致积压部分消息。
		重复消费：在触发rebalance机制时，可能原来消费者的offset还没有提交给broker，这个时候切换了消费者。那么如果新的消费者从旧的offset开始消费，那么就会有消息重复
				  也就是说，Consumer 2 并不会等待Consumer1提交完offset后，再进行Rebalance
