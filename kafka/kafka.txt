kafka高吞吐的实现：
1、顺序读写：
kafka的特点就是高性能，高吞吐，低延迟，吞吐量能达到几十万甚至几百万（增加分区，添加机器）
顺序读写：Kafka将消息写⼊到了分区partition中，⽽分区中消息是顺序读写的。磁盘顺序读写性
能要远⾼于内存的随机读写。
2、零拷贝：零拷⻉并不是不需要拷⻉，⽽是减少不必要的拷⻉次数。通常是说在IO读写过程中。Kafka利⽤linux操作系统的 "零拷⻉（zero-copy）" 机制在消费端做的优化。
	read：DMA付责将磁盘上的数据拷贝到内核空间。然后cpu付责将数据从内核空间拷贝到用户空间，用户才可以读取到数据
	write：用户写入数据在用户空间。cpu付责将用户空间的数据拷贝到内核空间，然后DMA付责将内核空间的数据拷贝到网卡中。
	因为CPU在内核和用户空间的上下文切换，以及数据拷贝，大大的降低了程序的执行性能。
	所以诞生了零拷贝技术：mmap。通过设置一块内存共享区域。通过内存映射文件的机制。减少一次cpu拷贝。大大提高了性能
3、批量发送：Kafka允许使⽤批量消息发送模式
4、消息压缩：Kafka⽀持对消息集合进⾏压缩
5、Page Cache
kafka利用操作系统的内存，而非jvm内存，避免了内存溢出和GC的问题

顺序写和随机写：
磁盘分为顺序读写
与随机读写，内存也⼀样分为顺序读写与随机读写。基于磁盘的随机读写确实很慢，但磁盘的顺序读
写性能却很⾼，⼀般⽽⾔要⾼出磁盘随机读写三个数量级，⼀些情况下磁盘顺序读写性能甚⾄要⾼于
内存随机读写。
 磁盘的顺序读写是磁盘使⽤模式中最有规律的，并且操作系统也对这种模式做了⼤量优化，Kafka
就是使⽤了磁盘顺序读写来提升的性能。Kafka的message是不断追加到本地磁盘⽂件末尾的，⽽不
是随机的写⼊，这使得Kafka写⼊吞吐量得到了显著提升

⚫kafka零拷贝原理



⚫Kafka生产和消费数据之所以快的几个原因。
一：Sender()子线程用到了批量发送消息。
二：Sender()子线程在写数据的时候，是直接写到了pageCache中，相当于到目前为止，数据都是在内存中操作。
三：操作系统在将PageCache中的数据写到硬盘的时候，用到了顺序写。
四：消费者在消费数据的时候，一旦在PageCache中找不到想要消费的数据，使用到了“预读”操作，将数据预读到PageCache中，这样有极大的概率会用到顺序读。顺序读 最终目的还是为了减少磁盘读取的寻道概率
五：消费者在消费数据的时候，会使用“零拷贝”技术，将PageCache中的数据直接拷贝到网卡设备，进而实现快速消费。
六：使用PageCache，省去了对JVM的GC操作，从而避免发生Stop the World。

⚫kafka之所以快的原因？
简单来说，是因为他充分利用了操作系统cache，顺序写和零拷贝技术。可以从 存储、访问， 两个方面分析。
存储
1.数据的写入利用了操作系统提供的pageCache，属于堆外内存，降低java应用内存的管理压力，从而减少了gc带来的stop the word问题，基于内存操作，且采取顺序写入方式，效率极快。
2.底层对于数据存储，分为了数据，索引，关系映射三种类型文件，采用顺序分段存储，稀疏索引的方式式。提高数据查找的效率。
访问
3.dma+sendfile  对于磁盘数据的读取，利用DMA（直接内存访问）的系统调用sendfile，由传统的 磁盘-内核缓冲-应用缓存-socket缓冲-网卡 文件copy方式，改进为 磁盘-内核缓冲-socket缓冲-网卡，减少了 用户/内核态的转换次数和 文件copy次数。
4.dma+mmap ，利用DMA提供的mmap函数调用，允许内核态缓冲区直接引用文件句柄，与用户态缓冲区内存共享，从而实现像访问内存那样直接访问文件。减少文件copy次数和态转换。


⚫kafka消费分区策略
Kafka为什么建议使用CooperativeStickyAssignor消费分区策略，在发送Rebalance的时候，CooperativeStickyAssignor 相比 RangeAssignor、RoundRobinAssignor 和 StickyAssignor 这三者分区分配策略，不会发生全局的Stop the World

⚫kafka的RecordAccumulator
	RecordAccumulator内部结构
	    private final ConcurrentMap<TopicPartition, Deque<ProducerBatch>> batches;
	    private final BufferPool free;
 当生产者发送消息时，会把消息放在一个暂存区域batches中，batches中key为topic和partition，value就是存储ProducerBatch的队列，这里时批量发消息的关键。也是kafka高性能的原因之一。
 kafka会把多条消息都放在ProducerBatch中，打包一起发送，当ProducerBatch写满的时候，就会唤醒sender子线程，然后把数据发送到leader所在的broker中的pagecache上，如果设置了多副本机制
 那么从节点follower就会从leader中拉取消息。当所有节点拉完消息，（acks=10，retries=10），这个时候会向生产者反馈一个ack应答，告诉生产者已经写入成功。但是消息此时在pagecache中，
 没有写入到硬盘上。如果此时机器挂了，那么这些数据就会丢失，
 注意：
 生产者发送失败ack应答失败，生产者会重新发送。
 acks应答参数：
 0：我的KafkaProducer在客户端，只要把消息发送出去，不管那条数据有没有发送出去，哪怕Partition Leader没有写入磁盘，也不管他了，直接认为这个消息发送成功
 1：只要Partition Leader接收到消息且写入本地磁盘，就认为成功，不管他其他的Follower有没有同步过去这条消息
 all：Partition Leader接收到消息之后，还必须要求ISR列表里跟Leader保持同步的那些Follower都要把消息同步过去，才认为这条消息是写入成功的。失败会重新发送
 retries：重新发送的次数
 设置参数：
 min.insync.replicas=2： Kafka ISR 列表中最小同步副本数
 replication.factor=3，用来设置主题的副本数。每个主题可以有多个副本，副本位于集群中不同的broker上，也就是说副本的数量不能超过broker的数量，否则创建主题时会失败。
 链接：https://www.bilibili.com/video/BV1Ss4y1h7ea/?spm_id_from=333.788&vd_source=80c3ca1a77e037f4d86501ba97d54dbb


⚫kafka会不会丢数据
即使我们把参数配置的很完善，也会丢失数据的两种场景：
一 当数据写到足够多的PageCache时，就会向生产者反馈acks响应，告知数据写入成功，但是如果此时，这些PageCache所在的操作系统挂了，如果数据还没写到硬盘上，这时数据就真的丢失了。
二 当副本数据所在的硬盘坏掉了，也会丢失数据。
注意：
我们可以改变以下参数来调整刷盘的频率，但是kafka官方不建议使用者调整。会影响kafka的性能，同时kafka官方认为可以用过副本机制来保证数据的可靠性
log.flush.interval.messages=10000 在持久化到磁盘前message最大接收条数。
log.flush.interval.ms=1000 任何主题中的消息在刷新到磁盘之前保留在内存中的最长时间（毫秒）。如果未设置，则使用 log.flush.scheduler.interval.ms 中的值
log.flush.scheduler.interval.ms 日志刷新程序检查是否需要将任何日志刷新到磁盘的频率（以毫秒为单位）

⚫kafka官网文档：https://kafka.apache.org/documentation.html#configuration
https://www.bilibili.com/video/BV1Ss4y1h7ea/?spm_id_from=333.788&vd_source=80c3ca1a77e037f4d86501ba97d54dbb

⚫如何尽量防止数据丢失呢？
将min.insync.replicas=2何止多副本，并设置log.dirs='多目录'：为了使每个目录对应一个独立的硬盘，防止硬盘坏了导致所有数据丢失

⚫kafka内存池化技术
Kafka通过使用内存缓冲池，让整个消息发送的过程中，内存空间可以循环利用，有效的降低了JVM GC的触发次数，从而提高了消息发送的速度，提升了吞吐量。
	RecordAccumulator内部结构
	    private final ConcurrentMap<TopicPartition, Deque<ProducerBatch>> batches;
	    private final BufferPool free;
	ProducerBatch内部结构：使用ByteBuffer来存储数据的。
	BufferPool：
		Deque<ByteBuffer> free 池化的空间
		nonPooledAvaliableMemory未被池化的可使用空间
	当生产者发送数据时，会根据消息体的大小向BufferPool申请一块内存16k大小的ByteBuffer，如果超过16k那么就向nonPooledAvaliableMemory申请一块内存空间来存放消息，
	因为对于磁化的空间中的内存是可以循环重复使用的，这块内存的使用和释放不需要等待GC来回收的，（就像线程池中的线程一样，一个道理，重复使用），
	没有GC的操作那么就不会发送STW，这也是kafka高性能，高吞吐的原因之一
	非磁化内存是需要GC来处理的，所以在生产中，我要尽量控制消息的大小，从而控制频繁的GC导致kafka的性能下降，（如果消息太大可以调整batch.size=16384）。
	
注意：
buffer.memory（默认32MB），这个参数代表的是RecordAccumulator所能容纳的最大的recordSize，其实这个参数经过层层传递，最终传给了BufferPool，由BufferPool来实际管理RecordAccumulator的容量。RecordAccumulator只需要关注自身的一些append、ready等等逻辑就好啦，职能很明确。
batch.size=16384设置ByteBuffer大小，一旦消息的大小达到这个值，就将消息发送给borker，
linger.ms默认0发送消息的延时时间，当达到这个时间，消息就会被发送到broker端，
compression.type消息压缩，减少占用的带宽（如果消费能力本身就不足，一般不建议压缩了，消息能力不足会消息积压，所以减少批量）
max.in.flight.requests.per.connection=5 指定了生产者在接收到服务器相应之前可以发送多个消息，值越高，占用的内存越大，当然也可以提升吞吐量，发生错误时，可能会造成数据的发送顺序改变，其默认值是5.
并且建议max.in.flight.requests.per.connection 的值小于 5。如何保证顺序，下面详解

⚫kafka消息顺序及幂等性问题
Kafka本身支持 At least once消息送达语义，因此实现消息发送的幂等关键是要实现 Broker端消息的去重。为了实现消息发送的幂等性，Kafka引入了两个新的概念：
【1】PID：每个新的 Producer在初始化的时候会被分配一个唯一的PID，这个 PID对用户是不可见的；
【2】Sequence Numbler：对于每个PID，该 Producer发送数据的每个<Topic, Partition>都对应一个从0开始单调递增的Sequence Number；
Broker端在内存中保存了这 Sequence Numbler，对于接收的每条消息，如果其序列号的值（SN_new）比 Broker端中维护的对应的序列号的值（SN_old）大1（即SN_new = SN_old + 1）时，Broker才会接收它，否则将其丢弃。这样就可以实现了消息重复提交了。但是，只能保证单个 Producer对于同一个 <Topic, Partition>的 Exactly Once语义。不能保证同一个Producer一个 Topic不同的 Partion幂等。
有序性：max.in.flight.requests.per.connection 小于等于 5，且开启幂等性enable.idempotence=true，broker 会对在途的请求按 SeqNum 排序，能保证分区消息的有序性


⚫消息如何发送到kafka集群的broker节点中
https://www.bilibili.com/video/BV1584y1H7BP/?spm_id_from=333.788&vd_source=80c3ca1a77e037f4d86501ba97d54dbb
链接：https://blog.csdn.net/muyimo/article/details/118877254
